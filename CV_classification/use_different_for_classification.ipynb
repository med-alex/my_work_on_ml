{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "5task_MedovikovAA.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "sourceId": 21154,
          "databundleVersionId": 1243559,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30628,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'tpu-getting-started:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F21154%2F1243559%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240207%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240207T130418Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5b55e81782654340fcb02731055400e18934a2cbeb694866fe80e47c6c020c9b3f7ae0fb9973cffea9a148817ea4287b18789f21345ea496221c801b649b7c868c7edaad2d3195213614d219c057133c0f4cb0baca4d17866cce929d6995b8c8b9ace8bd27549afe3c431e0710f3939403e6a940728fc335c891cf2d1a7e4d3ef426ec6a81e1d66ace3815dfa4c98c7b2821112190a6c9ab013d64433c64f20684101f4530478a5a11a7dcc6fa14f78f7796a7fbd4326ae2a015ce7cc3f6f915b37a215d2c4c55ac984944026698d80f9030af2bc4afaa8050fb45232f932e9d0a14c0f37ccacda6f4d1fd3dfe5f16dd57064b8f64a9157a426856954b82f4bc'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "gwnrb0tWq1Tb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка"
      ],
      "metadata": {
        "id": "Lj-6enEaSjRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорты"
      ],
      "metadata": {
        "id": "xzdqU20qSgXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q efficientnet"
      ],
      "metadata": {
        "id": "T389tp-5Nbsy",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:19:12.3563Z",
          "iopub.execute_input": "2024-01-04T20:19:12.356668Z",
          "iopub.status.idle": "2024-01-04T20:19:18.76624Z",
          "shell.execute_reply.started": "2024-01-04T20:19:12.356639Z",
          "shell.execute_reply": "2024-01-04T20:19:18.76536Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "# from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n",
        "# from tensorflow.keras.applications.nasnet import NASNetLarge\n",
        "from efficientnet.tfkeras import EfficientNetB7, EfficientNetL2, EfficientNetB0, EfficientNetB1"
      ],
      "metadata": {
        "id": "ye4Z9E1AQOoY",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:19:18.767909Z",
          "iopub.execute_input": "2024-01-04T20:19:18.76818Z",
          "iopub.status.idle": "2024-01-04T20:19:33.371233Z",
          "shell.execute_reply.started": "2024-01-04T20:19:18.768149Z",
          "shell.execute_reply": "2024-01-04T20:19:33.370448Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, GaussianDropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#  библиотека для работы с наборами данных на Kaggle\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "metadata": {
        "id": "mzNi7AywQSZh",
        "execution": {
          "iopub.status.busy": "2024-01-04T21:17:33.019856Z",
          "iopub.execute_input": "2024-01-04T21:17:33.020272Z",
          "iopub.status.idle": "2024-01-04T21:17:33.028617Z",
          "shell.execute_reply.started": "2024-01-04T21:17:33.020234Z",
          "shell.execute_reply": "2024-01-04T21:17:33.027628Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "# Обнаружение оборудования, возврат соответствующей стратегии распространения: TPU, GPU, CPU\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Обнаружение TPU. Параметры среды не требуются, если задана переменная среды TPU_NAME. На Kaggle это всегда так.\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # стратегия распространения по умолчанию в Tensorflow. Работает на CPU и одном GPU.\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "id": "UR8YoytpQWzM",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Данные"
      ],
      "metadata": {
        "id": "7SV7nmGcSduG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GCS_DS_PATH = 'gs://kds-dd5b7308dd0932436652aceb10f871ab80411ed4a570d2878ac7e9bf'"
      ],
      "metadata": {
        "id": "helZW6VE-JGl",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:19:51.569369Z",
          "iopub.execute_input": "2024-01-04T20:19:51.569757Z",
          "iopub.status.idle": "2024-01-04T20:19:51.573786Z",
          "shell.execute_reply.started": "2024-01-04T20:19:51.569725Z",
          "shell.execute_reply": "2024-01-04T20:19:51.572871Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
        "GCS_DS_PATH#получаем путь к наборам данных"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T21:17:35.9531Z",
          "iopub.execute_input": "2024-01-04T21:17:35.953517Z",
          "iopub.status.idle": "2024-01-04T21:17:35.960366Z",
          "shell.execute_reply.started": "2024-01-04T21:17:35.953479Z",
          "shell.execute_reply": "2024-01-04T21:17:35.959575Z"
        },
        "trusted": true,
        "id": "DtNBNLt7q1Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [512, 512] # при таком размере графическому процессору не хватит памяти. Используйте TPU\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "\n",
        "GCS_PATH_SELECT = { # available image sizes\n",
        "    192: GCS_DS_PATH + '/tfrecords-jpeg-192x192',\n",
        "    224: GCS_DS_PATH + '/tfrecords-jpeg-224x224',\n",
        "    331: GCS_DS_PATH + '/tfrecords-jpeg-331x331',\n",
        "    512: GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n",
        "}\n",
        "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec')\n",
        "\n",
        "SEED = 2020"
      ],
      "metadata": {
        "id": "sbSocB16Qw1C",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:19:53.123536Z",
          "iopub.execute_input": "2024-01-04T20:19:53.123875Z",
          "iopub.status.idle": "2024-01-04T20:19:53.948045Z",
          "shell.execute_reply.started": "2024-01-04T20:19:53.123845Z",
          "shell.execute_reply": "2024-01-04T20:19:53.946768Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции"
      ],
      "metadata": {
        "id": "t8vKbfhkSYwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_image(image_data):\n",
        "    \"\"\"Декодирует изображение в vyjujvthye. vfnhbwe (тензор)\n",
        "    Нормализует данные и преобразовывает изображения к указанному размеру\"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3) # Декодирование изображения в формате JPEG в тензор uint8.\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # преобразовать изображение в плавающее в диапазоне [0, 1]\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # явный размер, необходимый для TPU\n",
        "#     image = tf.keras.applications.inception_resnet_v2.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string означает байтовую строку\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # [] означает отдельный элемент\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT) # парсим отдельный пример в указанном формате\n",
        "    image = decode_image(example['image']) # преобразуем изображение к нужному нам формату\n",
        "    label = tf.cast(example['class'], tf.int32)\n",
        "    return image, label # возвращает набор данных пар (изображение, метка)\n",
        "\n",
        "def read_unlabeled_tfrecord(example):\n",
        "    UNLABELED_TFREC_FORMAT = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string означает байтовую строку\n",
        "        \"id\": tf.io.FixedLenFeature([], tf.string),  # [] означает отдельный элемент\n",
        "        # класс отсутствует, задача этого конкурса - предсказать классы цветов для тестового набора данных\n",
        "    }\n",
        "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image']) # преобразуем изображение к нужному нам формату\n",
        "    idnum = example['id']\n",
        "    return image, idnum # returns a dataset of image(s)\n",
        "\n",
        "def load_dataset(filenames, labeled=True, ordered=False):\n",
        "    \"\"\"Читает из TFRecords. Для оптимальной производительности одновременное чтение из нескольких\n",
        "    файлов без учета порядка данных. Порядок не имеет значения, поскольку мы все равно будем перетасовывать данные\"\"\"\n",
        "\n",
        "    ignore_order = tf.data.Options() # Представляет параметры для tf.data.Dataset.\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False # отключить порядок, увеличить скорость\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # автоматически чередует чтение из нескольких файлов\n",
        "    dataset = dataset.with_options(ignore_order) # использует данные сразу после их поступления, а не в исходном порядке\n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
        "    # возвращает набор данных пар (изображение, метка), если метка = Истина, или пар (изображение, идентификатор), если метка = Ложь\n",
        "    return dataset\n",
        "\n",
        "def data_augment(image, label):\n",
        "    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n",
        "    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n",
        "    # of the TPU while the TPU itself is computing gradients.\n",
        "    flag = random.randint(1,3)\n",
        "    # coef_1 = random.randint(70, 90) * 0.01\n",
        "    # coef_2 = random.randint(70, 90) * 0.01\n",
        "    if flag == 1:\n",
        "        image = tf.image.random_flip_left_right(image, seed=SEED)\n",
        "    elif flag == 2:\n",
        "        image = tf.image.random_flip_up_down(image, seed=SEED)\n",
        "    # else:\n",
        "        # image = tf.image.random_crop(image, [int(IMAGE_SIZE[0]*coef_1), int(IMAGE_SIZE[0]*coef_2), 3],seed=SEED, )\n",
        "    return image, label\n",
        "\n",
        "def get_training_dataset():\n",
        "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.repeat() # набор обучающих данных должен повторяться в течение нескольких эпох\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) #готовим следующий набор, пока предыдущий обучается\n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset():\n",
        "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=False)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache() # кешируем набор\n",
        "    dataset = dataset.prefetch(AUTO) #готовим следующий набор, пока предыдущий обучается\n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) #готовим следующий набор, пока предыдущий обучается\n",
        "    return dataset\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
        "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
        "STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
      ],
      "metadata": {
        "id": "s2dTAOKTRD8I",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:19:56.046615Z",
          "iopub.execute_input": "2024-01-04T20:19:56.047043Z",
          "iopub.status.idle": "2024-01-04T20:19:56.06467Z",
          "shell.execute_reply.started": "2024-01-04T20:19:56.047003Z",
          "shell.execute_reply": "2024-01-04T20:19:56.063722Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(use_model, weights):\n",
        "    # noisy-student\n",
        "    base_model = use_model(weights=weights,\n",
        "                      include_top=False, pooling='avg',\n",
        "                      input_shape=(*IMAGE_SIZE, 3))\n",
        "#     base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    predictions = Dense(104, activation='softmax')(x)\n",
        "    return Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "MopXK60mReQJ",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:19:59.782493Z",
          "iopub.execute_input": "2024-01-04T20:19:59.782885Z",
          "iopub.status.idle": "2024-01-04T20:19:59.788343Z",
          "shell.execute_reply.started": "2024-01-04T20:19:59.782852Z",
          "shell.execute_reply": "2024-01-04T20:19:59.78734Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_score(history):\n",
        "\n",
        "  plt.plot(history.history['sparse_categorical_accuracy'],\n",
        "          label='Оценка точности на обучающем наборе')\n",
        "  plt.plot(history.history['val_sparse_categorical_accuracy'],\n",
        "          label='Оценка точности на проверочном наборе')\n",
        "  plt.xlabel('Эпоха обучения')\n",
        "  plt.ylabel('Оценка точности')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def print_loss(history):\n",
        "\n",
        "  plt.plot(history.history['loss'],\n",
        "         label='Оценка потерь на обучающем наборе')\n",
        "  plt.plot(history.history['val_loss'],\n",
        "          label='Оценка потерь на проверочном наборе')\n",
        "  plt.xlabel('Эпоха обучения')\n",
        "  plt.ylabel('Оценка потерь')\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "-U6faL8FSwIH",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:20:01.354611Z",
          "iopub.execute_input": "2024-01-04T20:20:01.355245Z",
          "iopub.status.idle": "2024-01-04T20:20:01.362621Z",
          "shell.execute_reply.started": "2024-01-04T20:20:01.355166Z",
          "shell.execute_reply": "2024-01-04T20:20:01.361597Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Датасеты"
      ],
      "metadata": {
        "id": "SCyCiZ6gSU4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = get_training_dataset()\n",
        "validation_dataset = get_validation_dataset()"
      ],
      "metadata": {
        "id": "85azqj1eRv26",
        "execution": {
          "iopub.status.busy": "2024-01-04T20:20:04.272092Z",
          "iopub.execute_input": "2024-01-04T20:20:04.273086Z",
          "iopub.status.idle": "2024-01-04T20:20:04.857986Z",
          "shell.execute_reply.started": "2024-01-04T20:20:04.273039Z",
          "shell.execute_reply": "2024-01-04T20:20:04.856793Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG19"
      ],
      "metadata": {
        "id": "_NVRjVv-RgwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    vgg_model = get_model(VGG19, 'imagenet') # тут подставить свою модель\n",
        "\n",
        "vgg_model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "oMIbRnAhRhC6",
        "execution": {
          "iopub.status.busy": "2024-01-04T17:17:49.597223Z",
          "iopub.execute_input": "2024-01-04T17:17:49.597643Z",
          "iopub.status.idle": "2024-01-04T17:17:56.360828Z",
          "shell.execute_reply.started": "2024-01-04T17:17:49.597608Z",
          "shell.execute_reply": "2024-01-04T17:17:56.359942Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_EPOCHS = 30"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T17:38:14.168059Z",
          "iopub.execute_input": "2024-01-04T17:38:14.168512Z",
          "iopub.status.idle": "2024-01-04T17:38:14.173115Z",
          "shell.execute_reply.started": "2024-01-04T17:38:14.168472Z",
          "shell.execute_reply": "2024-01-04T17:38:14.172133Z"
        },
        "trusted": true,
        "id": "B5ENmcl0q1Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_START = 0.00001\n",
        "LR_MAX = 0.00005 * strategy.num_replicas_in_sync#0.0001\n",
        "LR_MIN = 0.00001\n",
        "LR_RAMPUP_EPOCHS = 10\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_EXP_DECAY = .75\n",
        "\n",
        "def vgg_lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "\n",
        "vgg_lr_callback = tf.keras.callbacks.LearningRateScheduler(vgg_lrfn, verbose=True)\n",
        "\n",
        "# построим график изменения шага обучение в зависимости от эпох\n",
        "rng = [i for i in range(VGG_EPOCHS)]\n",
        "y = [vgg_lrfn(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "id": "zcHCLCg0RWbZ",
        "execution": {
          "iopub.status.busy": "2024-01-04T17:38:15.275944Z",
          "iopub.execute_input": "2024-01-04T17:38:15.27631Z",
          "iopub.status.idle": "2024-01-04T17:38:15.433944Z",
          "shell.execute_reply.started": "2024-01-04T17:38:15.276279Z",
          "shell.execute_reply": "2024-01-04T17:38:15.432919Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_vgg = vgg_model.fit(training_dataset,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          epochs=VGG_EPOCHS,\n",
        "          callbacks=[vgg_lr_callback, ModelCheckpoint(filepath='VGG19.h5',\n",
        "                                                      monitor='val_loss',\n",
        "                                                      save_best_only=True)],\n",
        "          validation_data=validation_dataset,\n",
        "          workers = 3)"
      ],
      "metadata": {
        "id": "YmXEG7HkR-4p",
        "execution": {
          "iopub.status.busy": "2024-01-04T17:38:28.133021Z",
          "iopub.execute_input": "2024-01-04T17:38:28.133465Z",
          "iopub.status.idle": "2024-01-04T18:18:29.173669Z",
          "shell.execute_reply.started": "2024-01-04T17:38:28.133428Z",
          "shell.execute_reply": "2024-01-04T18:18:29.17243Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(history_vgg)\n",
        "print_loss(history_vgg)"
      ],
      "metadata": {
        "id": "rnVBiUSbTGMB",
        "execution": {
          "iopub.status.busy": "2024-01-04T18:18:29.176048Z",
          "iopub.execute_input": "2024-01-04T18:18:29.176353Z",
          "iopub.status.idle": "2024-01-04T18:18:29.488074Z",
          "shell.execute_reply.started": "2024-01-04T18:18:29.176325Z",
          "shell.execute_reply": "2024-01-04T18:18:29.487138Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionResNetV2"
      ],
      "metadata": {
        "id": "mJqnLnxLq1Tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    inception_model = get_model(InceptionResNetV2, 'imagenet') # тут подставить свою модель\n",
        "\n",
        "inception_model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T18:25:21.503803Z",
          "iopub.execute_input": "2024-01-04T18:25:21.504234Z",
          "iopub.status.idle": "2024-01-04T18:25:57.169756Z",
          "shell.execute_reply.started": "2024-01-04T18:25:21.504198Z",
          "shell.execute_reply": "2024-01-04T18:25:57.168595Z"
        },
        "trusted": true,
        "id": "Kj132ZV5q1Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INCEPTION_EPOCHS = 15"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T18:26:34.946637Z",
          "iopub.execute_input": "2024-01-04T18:26:34.947438Z",
          "iopub.status.idle": "2024-01-04T18:26:34.951545Z",
          "shell.execute_reply.started": "2024-01-04T18:26:34.94739Z",
          "shell.execute_reply": "2024-01-04T18:26:34.950598Z"
        },
        "trusted": true,
        "id": "O5KAV5sKq1Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_START = 0.00001\n",
        "LR_MAX = 0.00005 * strategy.num_replicas_in_sync#0.0001\n",
        "LR_MIN = 0.00001\n",
        "LR_RAMPUP_EPOCHS = 8\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_EXP_DECAY = .7\n",
        "\n",
        "def inception_lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "\n",
        "inception_lr_callback = tf.keras.callbacks.LearningRateScheduler(inception_lrfn, verbose=True)\n",
        "\n",
        "# построим график изменения шага обучение в зависимости от эпох\n",
        "rng = [i for i in range(INCEPTION_EPOCHS)]\n",
        "y = [inception_lrfn(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T18:27:09.380851Z",
          "iopub.execute_input": "2024-01-04T18:27:09.381362Z",
          "iopub.status.idle": "2024-01-04T18:27:09.542371Z",
          "shell.execute_reply.started": "2024-01-04T18:27:09.381307Z",
          "shell.execute_reply": "2024-01-04T18:27:09.541536Z"
        },
        "trusted": true,
        "id": "stUPt7uOq1Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_inception = inception_model.fit(training_dataset,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          epochs=INCEPTION_EPOCHS,\n",
        "          callbacks=[inception_lr_callback, ModelCheckpoint(filepath='INCEPTION.h5',\n",
        "                                                            monitor='val_loss',\n",
        "                                                            save_best_only=True)],\n",
        "          validation_data=validation_dataset,\n",
        "          workers = 3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T18:27:42.480998Z",
          "iopub.execute_input": "2024-01-04T18:27:42.481431Z",
          "iopub.status.idle": "2024-01-04T18:55:52.223707Z",
          "shell.execute_reply.started": "2024-01-04T18:27:42.481388Z",
          "shell.execute_reply": "2024-01-04T18:55:52.222517Z"
        },
        "trusted": true,
        "id": "DIDEBuQmq1Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(history_inception)\n",
        "print_loss(history_inception)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T18:55:52.226268Z",
          "iopub.execute_input": "2024-01-04T18:55:52.226566Z",
          "iopub.status.idle": "2024-01-04T18:55:52.528903Z",
          "shell.execute_reply.started": "2024-01-04T18:55:52.226538Z",
          "shell.execute_reply": "2024-01-04T18:55:52.527959Z"
        },
        "trusted": true,
        "id": "pFGbviqBq1Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xception"
      ],
      "metadata": {
        "id": "ITblh5tDq1Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    xception_model = get_model(Xception, 'imagenet') # тут подставить свою модель\n",
        "\n",
        "xception_model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:04:30.778069Z",
          "iopub.execute_input": "2024-01-04T19:04:30.778868Z",
          "iopub.status.idle": "2024-01-04T19:04:38.99897Z",
          "shell.execute_reply.started": "2024-01-04T19:04:30.778829Z",
          "shell.execute_reply": "2024-01-04T19:04:38.997895Z"
        },
        "trusted": true,
        "id": "wZcui-1jq1Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XCEPTION_EPOCHS = 15"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:04:45.945554Z",
          "iopub.execute_input": "2024-01-04T19:04:45.945938Z",
          "iopub.status.idle": "2024-01-04T19:04:45.950142Z",
          "shell.execute_reply.started": "2024-01-04T19:04:45.945904Z",
          "shell.execute_reply": "2024-01-04T19:04:45.949337Z"
        },
        "trusted": true,
        "id": "An9SicKgq1Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_START = 0.00001\n",
        "LR_MAX = 0.00005 * strategy.num_replicas_in_sync#0.0001\n",
        "LR_MIN = 0.00001\n",
        "LR_RAMPUP_EPOCHS = 8\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_EXP_DECAY = .7\n",
        "\n",
        "def xception_lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "\n",
        "xception_lr_callback = tf.keras.callbacks.LearningRateScheduler(xception_lrfn, verbose=True)\n",
        "\n",
        "# построим график изменения шага обучение в зависимости от эпох\n",
        "rng = [i for i in range(XCEPTION_EPOCHS)]\n",
        "y = [xception_lrfn(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:04:49.102418Z",
          "iopub.execute_input": "2024-01-04T19:04:49.10279Z",
          "iopub.status.idle": "2024-01-04T19:04:49.276285Z",
          "shell.execute_reply.started": "2024-01-04T19:04:49.10276Z",
          "shell.execute_reply": "2024-01-04T19:04:49.275354Z"
        },
        "trusted": true,
        "id": "w4Qk9dHOq1Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_xception = xception_model.fit(training_dataset,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          epochs=XCEPTION_EPOCHS,\n",
        "          callbacks=[xception_lr_callback, ModelCheckpoint(filepath='XCEPTION.h5',\n",
        "                                                            monitor='val_loss',\n",
        "                                                            save_best_only=True)],\n",
        "          validation_data=validation_dataset,\n",
        "          workers = 3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:05:30.586515Z",
          "iopub.execute_input": "2024-01-04T19:05:30.586867Z",
          "iopub.status.idle": "2024-01-04T19:25:13.831585Z",
          "shell.execute_reply.started": "2024-01-04T19:05:30.586837Z",
          "shell.execute_reply": "2024-01-04T19:25:13.830373Z"
        },
        "trusted": true,
        "id": "5ll6raudq1Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(history_xception)\n",
        "print_loss(history_xception)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:25:13.833895Z",
          "iopub.execute_input": "2024-01-04T19:25:13.834342Z",
          "iopub.status.idle": "2024-01-04T19:25:14.179408Z",
          "shell.execute_reply.started": "2024-01-04T19:25:13.834308Z",
          "shell.execute_reply": "2024-01-04T19:25:14.178223Z"
        },
        "trusted": true,
        "id": "xQDIeEgxq1Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet152V2"
      ],
      "metadata": {
        "id": "mHcGvjlmq1Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    resnet_model = get_model(ResNet152V2, 'imagenet') # тут подставить свою модель\n",
        "\n",
        "resnet_model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:28:48.625499Z",
          "iopub.execute_input": "2024-01-04T19:28:48.626443Z",
          "iopub.status.idle": "2024-01-04T19:29:23.069206Z",
          "shell.execute_reply.started": "2024-01-04T19:28:48.626402Z",
          "shell.execute_reply": "2024-01-04T19:29:23.067956Z"
        },
        "trusted": true,
        "id": "cbLFaieBq1Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESNET_EPOCHS = 15"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:33:32.029844Z",
          "iopub.execute_input": "2024-01-04T19:33:32.030235Z",
          "iopub.status.idle": "2024-01-04T19:33:32.034548Z",
          "shell.execute_reply.started": "2024-01-04T19:33:32.030201Z",
          "shell.execute_reply": "2024-01-04T19:33:32.033518Z"
        },
        "trusted": true,
        "id": "DztHIMTCq1Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_START = 0.00001\n",
        "LR_MAX = 0.00005 * strategy.num_replicas_in_sync#0.0001\n",
        "LR_MIN = 0.00001\n",
        "LR_RAMPUP_EPOCHS = 8\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_EXP_DECAY = .7\n",
        "\n",
        "def resnet_lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "\n",
        "resnet_lr_callback = tf.keras.callbacks.LearningRateScheduler(resnet_lrfn, verbose=True)\n",
        "\n",
        "# построим график изменения шага обучение в зависимости от эпох\n",
        "rng = [i for i in range(RESNET_EPOCHS)]\n",
        "y = [resnet_lrfn(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:33:32.986631Z",
          "iopub.execute_input": "2024-01-04T19:33:32.986967Z",
          "iopub.status.idle": "2024-01-04T19:33:33.150636Z",
          "shell.execute_reply.started": "2024-01-04T19:33:32.986941Z",
          "shell.execute_reply": "2024-01-04T19:33:33.149522Z"
        },
        "trusted": true,
        "id": "RAafocB6q1Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet = resnet_model.fit(training_dataset,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          epochs=RESNET_EPOCHS,\n",
        "          callbacks=[resnet_lr_callback, ModelCheckpoint(filepath='RESNET.h5',\n",
        "                                                            monitor='val_loss',\n",
        "                                                            save_best_only=True)],\n",
        "          validation_data=validation_dataset,\n",
        "          workers = 3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T19:37:50.842699Z",
          "iopub.execute_input": "2024-01-04T19:37:50.843615Z",
          "iopub.status.idle": "2024-01-04T20:01:04.724029Z",
          "shell.execute_reply.started": "2024-01-04T19:37:50.843565Z",
          "shell.execute_reply": "2024-01-04T20:01:04.722752Z"
        },
        "trusted": true,
        "id": "RwqKq4Hkq1UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(history_resnet)\n",
        "print_loss(history_resnet)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T20:01:04.72931Z",
          "iopub.execute_input": "2024-01-04T20:01:04.729598Z",
          "iopub.status.idle": "2024-01-04T20:01:05.035411Z",
          "shell.execute_reply.started": "2024-01-04T20:01:04.72957Z",
          "shell.execute_reply": "2024-01-04T20:01:05.034433Z"
        },
        "trusted": true,
        "id": "KVHn5EqGq1UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB7"
      ],
      "metadata": {
        "id": "T69TbmXSq1UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    efficientnet_model = get_model(EfficientNetB7, 'noisy-student') # тут подставить свою модель\n",
        "\n",
        "efficientnet_model.compile(\n",
        "    optimizer='nadam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T20:20:13.696918Z",
          "iopub.execute_input": "2024-01-04T20:20:13.697778Z",
          "iopub.status.idle": "2024-01-04T20:21:11.66699Z",
          "shell.execute_reply.started": "2024-01-04T20:20:13.697737Z",
          "shell.execute_reply": "2024-01-04T20:21:11.665848Z"
        },
        "trusted": true,
        "id": "l0Aly8NQq1UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EFFICIENTNET_EPOCHS = 15"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T20:21:11.668734Z",
          "iopub.execute_input": "2024-01-04T20:21:11.669039Z",
          "iopub.status.idle": "2024-01-04T20:21:11.673011Z",
          "shell.execute_reply.started": "2024-01-04T20:21:11.669007Z",
          "shell.execute_reply": "2024-01-04T20:21:11.672203Z"
        },
        "trusted": true,
        "id": "1Ds42D_Fq1UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_START = 0.00001\n",
        "LR_MAX = 0.00005 * strategy.num_replicas_in_sync#0.0001\n",
        "LR_MIN = 0.00001\n",
        "LR_RAMPUP_EPOCHS = 8\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_EXP_DECAY = .7\n",
        "\n",
        "def efficientnet_lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "\n",
        "efficientnet_lr_callback = tf.keras.callbacks.LearningRateScheduler(efficientnet_lrfn, verbose=True)\n",
        "\n",
        "# построим график изменения шага обучение в зависимости от эпох\n",
        "rng = [i for i in range(EFFICIENTNET_EPOCHS)]\n",
        "y = [efficientnet_lrfn(x) for x in rng]\n",
        "plt.plot(rng, y)\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T20:21:11.674Z",
          "iopub.execute_input": "2024-01-04T20:21:11.674261Z",
          "iopub.status.idle": "2024-01-04T20:21:11.850438Z",
          "shell.execute_reply.started": "2024-01-04T20:21:11.674233Z",
          "shell.execute_reply": "2024-01-04T20:21:11.849661Z"
        },
        "trusted": true,
        "id": "KxZgnZChq1UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_efficientnet = efficientnet_model.fit(training_dataset,\n",
        "          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          epochs=EFFICIENTNET_EPOCHS,\n",
        "          callbacks=[efficientnet_lr_callback, ModelCheckpoint(filepath='EFFICIENTNET.h5',\n",
        "                                                            monitor='val_loss',\n",
        "                                                            save_best_only=True)],\n",
        "          validation_data=validation_dataset,\n",
        "          workers = 3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T20:21:11.851947Z",
          "iopub.execute_input": "2024-01-04T20:21:11.852193Z",
          "iopub.status.idle": "2024-01-04T21:03:42.827733Z",
          "shell.execute_reply.started": "2024-01-04T20:21:11.852161Z",
          "shell.execute_reply": "2024-01-04T21:03:42.826395Z"
        },
        "trusted": true,
        "id": "AbCcYIEJq1UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_score(history_efficientnet)\n",
        "print_loss(history_efficientnet)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T21:03:42.829921Z",
          "iopub.execute_input": "2024-01-04T21:03:42.830222Z",
          "iopub.status.idle": "2024-01-04T21:03:43.130302Z",
          "shell.execute_reply.started": "2024-01-04T21:03:42.830191Z",
          "shell.execute_reply": "2024-01-04T21:03:43.129241Z"
        },
        "trusted": true,
        "id": "m44jzNrQq1UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тест на submission"
      ],
      "metadata": {
        "id": "0JLdjVvsq1UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = get_test_dataset(ordered=True)\n",
        "\n",
        "print('Вычисляем предсказания...')\n",
        "test_images_ds = test_ds.map(lambda image, idnum: image)\n",
        "probabilities = efficientnet_model.predict(test_images_ds)\n",
        "predictions = np.argmax(probabilities, axis=-1)\n",
        "print(predictions)\n",
        "\n",
        "print('Создание файла submission.csv...')\n",
        "test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n",
        "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # все в одной партии\n",
        "np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-04T21:09:06.988137Z",
          "iopub.execute_input": "2024-01-04T21:09:06.988666Z",
          "iopub.status.idle": "2024-01-04T21:10:35.29065Z",
          "shell.execute_reply.started": "2024-01-04T21:09:06.988624Z",
          "shell.execute_reply": "2024-01-04T21:10:35.289572Z"
        },
        "trusted": true,
        "id": "aE1rX5U1q1UL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}